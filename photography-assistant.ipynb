{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10500315,"sourceType":"datasetVersion","datasetId":6445789},{"sourceId":222565,"sourceType":"modelInstanceVersion","modelInstanceId":189859,"modelId":211859},{"sourceId":222567,"sourceType":"modelInstanceVersion","modelInstanceId":189861,"modelId":211861},{"sourceId":222606,"sourceType":"modelInstanceVersion","modelInstanceId":189897,"modelId":211894}],"dockerImageVersionId":30822,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport cv2 as cv\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom tensorflow.keras.models import load_model\nfrom keras.losses import MeanSquaredError\nfrom IPython import display\nfrom PIL import Image","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-17T19:27:16.980497Z","iopub.execute_input":"2025-01-17T19:27:16.980691Z","iopub.status.idle":"2025-01-17T19:27:25.179033Z","shell.execute_reply.started":"2025-01-17T19:27:16.980672Z","shell.execute_reply":"2025-01-17T19:27:25.178379Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"denoising = load_model(\"/kaggle/input/noise/pytorch/default/1/denoising_model.h5\",\n                       custom_objects={'mse': MeanSquaredError()})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-17T19:27:35.043832Z","iopub.execute_input":"2025-01-17T19:27:35.044124Z","iopub.status.idle":"2025-01-17T19:27:35.930611Z","shell.execute_reply.started":"2025-01-17T19:27:35.044099Z","shell.execute_reply":"2025-01-17T19:27:35.929949Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"denoising.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-17T19:27:37.890926Z","iopub.execute_input":"2025-01-17T19:27:37.891220Z","iopub.status.idle":"2025-01-17T19:27:37.912231Z","shell.execute_reply.started":"2025-01-17T19:27:37.891197Z","shell.execute_reply":"2025-01-17T19:27:37.911450Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"light_enhancement = load_model(\"/kaggle/input/enhancement/tensorflow2/default/1/lowlightenhancefinal.h5\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-17T19:27:40.496864Z","iopub.execute_input":"2025-01-17T19:27:40.497192Z","iopub.status.idle":"2025-01-17T19:27:41.393918Z","shell.execute_reply.started":"2025-01-17T19:27:40.497166Z","shell.execute_reply":"2025-01-17T19:27:41.393203Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"light_enhancement.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-17T19:27:43.280042Z","iopub.execute_input":"2025-01-17T19:27:43.280328Z","iopub.status.idle":"2025-01-17T19:27:43.311322Z","shell.execute_reply.started":"2025-01-17T19:27:43.280306Z","shell.execute_reply":"2025-01-17T19:27:43.310543Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"resolution = load_model(\"/kaggle/input/resolution/tensorflow2/default/1/img_resolution.h5\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-17T19:27:46.208457Z","iopub.execute_input":"2025-01-17T19:27:46.208736Z","iopub.status.idle":"2025-01-17T19:27:46.979827Z","shell.execute_reply.started":"2025-01-17T19:27:46.208715Z","shell.execute_reply":"2025-01-17T19:27:46.979152Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"resolution.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-17T19:28:00.097715Z","iopub.execute_input":"2025-01-17T19:28:00.098044Z","iopub.status.idle":"2025-01-17T19:28:00.138692Z","shell.execute_reply.started":"2025-01-17T19:28:00.098019Z","shell.execute_reply":"2025-01-17T19:28:00.137945Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def show_images(input,output):\n    plt.figure(figsize=(12, 4))\n    plt.subplot(1, 3, 1)\n    plt.title(\"Input\")\n    plt.imshow(input)\n    plt.axis('off')  \n\n    plt.subplot(1, 3, 2)\n    plt.title(\"Output\")\n    plt.imshow(output)\n    plt.axis('off')\n\n    plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-17T19:28:08.015553Z","iopub.execute_input":"2025-01-17T19:28:08.015846Z","iopub.status.idle":"2025-01-17T19:28:08.020969Z","shell.execute_reply.started":"2025-01-17T19:28:08.015824Z","shell.execute_reply":"2025-01-17T19:28:08.020014Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def predict_images4(input_img, enhanced, denoised, output):\n    plt.figure(figsize=(16, 4))\n    \n    plt.subplot(1, 4, 1)\n    plt.title(\"Input Image\")\n    plt.imshow(input_img)\n    plt.axis('off')\n    \n    plt.subplot(1, 4, 2)\n    plt.title(\"Processed1 Image\")\n    plt.imshow(enhanced)\n    plt.axis('off')\n    \n    plt.subplot(1, 4, 3)\n    plt.title(\"Processed2 Image\")\n    plt.imshow(denoised)\n    plt.axis('off')\n    \n    plt.subplot(1, 4, 4)\n    plt.title(\"Output Image\")\n    plt.imshow(output)\n    plt.axis('off')\n    \n    plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-17T19:28:09.769224Z","iopub.execute_input":"2025-01-17T19:28:09.769601Z","iopub.status.idle":"2025-01-17T19:28:09.774695Z","shell.execute_reply.started":"2025-01-17T19:28:09.769577Z","shell.execute_reply":"2025-01-17T19:28:09.773871Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def predict_images3(input_img, enhanced, denoised):\n    plt.figure(figsize=(16, 4))\n    \n    plt.subplot(1, 4, 1)\n    plt.title(\"Input Image\")\n    plt.imshow(input_img)\n    plt.axis('off')\n    \n    plt.subplot(1, 4, 2)\n    plt.title(\"Processed Image\")\n    plt.imshow(enhanced)\n    plt.axis('off')\n\n    plt.subplot(1, 4, 3)\n    plt.title(\"Output Image\")\n    plt.imshow(denoised)\n    plt.axis('off')\n    \n    plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-17T19:28:12.001516Z","iopub.execute_input":"2025-01-17T19:28:12.001813Z","iopub.status.idle":"2025-01-17T19:28:12.006630Z","shell.execute_reply.started":"2025-01-17T19:28:12.001788Z","shell.execute_reply":"2025-01-17T19:28:12.005861Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"input = \"/kaggle/input/final-testing/test_img.png\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-17T19:28:13.721087Z","iopub.execute_input":"2025-01-17T19:28:13.721413Z","iopub.status.idle":"2025-01-17T19:28:13.725172Z","shell.execute_reply.started":"2025-01-17T19:28:13.721387Z","shell.execute_reply":"2025-01-17T19:28:13.724257Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"img = cv.imread(input, cv.IMREAD_COLOR) \nimg = cv.cvtColor(img, cv.COLOR_BGR2RGB)\nimg = cv.resize(img, (256, 256))\nimg = img.astype('float32') / 255.0\n\nimg_tensortest = tf.convert_to_tensor(img, dtype=tf.float32)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-17T19:28:15.505614Z","iopub.execute_input":"2025-01-17T19:28:15.505892Z","iopub.status.idle":"2025-01-17T19:28:15.546180Z","shell.execute_reply.started":"2025-01-17T19:28:15.505871Z","shell.execute_reply":"2025-01-17T19:28:15.545560Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"if isinstance(input, str):  # If it's a file path\n    input_img = cv.cvtColor(cv.imread(input), cv.COLOR_BGR2RGB)\n    input_img = input_img.astype('float32') / 255.0  # Normalize to [0, 1]\nelif isinstance(input, np.ndarray):  # If it's already an array\n    input_img = (input * 255).astype('uint8')\nelse:  # Handle tensors\n    input_img = (input.numpy() * 255).astype('uint8')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-17T19:28:17.376966Z","iopub.execute_input":"2025-01-17T19:28:17.377299Z","iopub.status.idle":"2025-01-17T19:28:17.385321Z","shell.execute_reply.started":"2025-01-17T19:28:17.377273Z","shell.execute_reply":"2025-01-17T19:28:17.384559Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"denoised = denoising.predict(np.expand_dims(img_tensortest, axis=0))[0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-17T19:28:19.347083Z","iopub.execute_input":"2025-01-17T19:28:19.347425Z","iopub.status.idle":"2025-01-17T19:28:21.196608Z","shell.execute_reply.started":"2025-01-17T19:28:19.347391Z","shell.execute_reply":"2025-01-17T19:28:21.195851Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"enhanced = light_enhancement.predict(np.expand_dims(denoised, axis=0))[0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-17T19:28:21.197770Z","iopub.execute_input":"2025-01-17T19:28:21.198079Z","iopub.status.idle":"2025-01-17T19:28:24.943283Z","shell.execute_reply.started":"2025-01-17T19:28:21.198055Z","shell.execute_reply":"2025-01-17T19:28:24.942592Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"predict_images3(input_img,denoised,enhanced)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-17T19:28:24.944555Z","iopub.execute_input":"2025-01-17T19:28:24.944814Z","iopub.status.idle":"2025-01-17T19:28:25.319050Z","shell.execute_reply.started":"2025-01-17T19:28:24.944792Z","shell.execute_reply":"2025-01-17T19:28:25.318242Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"input = \"/kaggle/input/final-testing/test2_img.png\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-17T19:28:28.866145Z","iopub.execute_input":"2025-01-17T19:28:28.866471Z","iopub.status.idle":"2025-01-17T19:28:28.870165Z","shell.execute_reply.started":"2025-01-17T19:28:28.866446Z","shell.execute_reply":"2025-01-17T19:28:28.869179Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"img = cv.imread(input, cv.IMREAD_COLOR) \nimg = cv.cvtColor(img, cv.COLOR_BGR2RGB)\nimg = cv.resize(img, (256, 256))\nimg = img.astype('float32') / 255.0\n\nimg_tensortest = tf.convert_to_tensor(img, dtype=tf.float32)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-17T19:28:31.108569Z","iopub.execute_input":"2025-01-17T19:28:31.108851Z","iopub.status.idle":"2025-01-17T19:28:31.131930Z","shell.execute_reply.started":"2025-01-17T19:28:31.108830Z","shell.execute_reply":"2025-01-17T19:28:31.130963Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"if isinstance(input, str):  # If it's a file path\n    input_img = cv.cvtColor(cv.imread(input), cv.COLOR_BGR2RGB)\n    input_img = input_img.astype('float32') / 255.0  # Normalize to [0, 1]\nelif isinstance(input, np.ndarray):  # If it's already an array\n    input_img = (input * 255).astype('uint8')\nelse:  # Handle tensors\n    input_img = (input.numpy() * 255).astype('uint8')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-17T19:28:33.277138Z","iopub.execute_input":"2025-01-17T19:28:33.277481Z","iopub.status.idle":"2025-01-17T19:28:33.283927Z","shell.execute_reply.started":"2025-01-17T19:28:33.277453Z","shell.execute_reply":"2025-01-17T19:28:33.283103Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"denoised = denoising.predict(np.expand_dims(img_tensortest, axis=0))[0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-17T19:28:34.983098Z","iopub.execute_input":"2025-01-17T19:28:34.983463Z","iopub.status.idle":"2025-01-17T19:28:35.046924Z","shell.execute_reply.started":"2025-01-17T19:28:34.983431Z","shell.execute_reply":"2025-01-17T19:28:35.046288Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"enhanced = light_enhancement.predict(np.expand_dims(denoised, axis=0))[0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-17T19:28:36.783476Z","iopub.execute_input":"2025-01-17T19:28:36.783823Z","iopub.status.idle":"2025-01-17T19:28:36.851756Z","shell.execute_reply.started":"2025-01-17T19:28:36.783796Z","shell.execute_reply":"2025-01-17T19:28:36.850847Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"predict_images3(input_img,denoised,enhanced)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-17T19:28:39.149142Z","iopub.execute_input":"2025-01-17T19:28:39.149494Z","iopub.status.idle":"2025-01-17T19:28:39.474846Z","shell.execute_reply.started":"2025-01-17T19:28:39.149462Z","shell.execute_reply":"2025-01-17T19:28:39.473901Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"input3 = \"/kaggle/input/final-testing/test3_img.png\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-17T19:28:43.943634Z","iopub.execute_input":"2025-01-17T19:28:43.943926Z","iopub.status.idle":"2025-01-17T19:28:43.947662Z","shell.execute_reply.started":"2025-01-17T19:28:43.943903Z","shell.execute_reply":"2025-01-17T19:28:43.946915Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"img = cv.imread(input3, cv.IMREAD_COLOR) \nimg = cv.cvtColor(img, cv.COLOR_BGR2RGB)\nimg = cv.resize(img, (256, 256))\nimg = img.astype('float32') / 255.0\n\nimg_tensortest = tf.convert_to_tensor(img, dtype=tf.float32)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-17T19:28:45.604723Z","iopub.execute_input":"2025-01-17T19:28:45.605001Z","iopub.status.idle":"2025-01-17T19:28:45.646773Z","shell.execute_reply.started":"2025-01-17T19:28:45.604977Z","shell.execute_reply":"2025-01-17T19:28:45.646121Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"if isinstance(input3, str):  # If it's a file path\n    input_img = cv.cvtColor(cv.imread(input3), cv.COLOR_BGR2RGB)\n    input_img = input_img.astype('float32') / 255.0  # Normalize to [0, 1]\nelif isinstance(input3, np.ndarray):  # If it's already an array\n    input_img = (input3 * 255).astype('uint8')\nelse:  # Handle tensors\n    input_img = (input3.numpy() * 255).astype('uint8')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-17T19:28:47.895462Z","iopub.execute_input":"2025-01-17T19:28:47.895757Z","iopub.status.idle":"2025-01-17T19:28:47.912506Z","shell.execute_reply.started":"2025-01-17T19:28:47.895733Z","shell.execute_reply":"2025-01-17T19:28:47.911537Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"denoised = denoising.predict(np.expand_dims(img_tensortest, axis=0))[0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-17T19:28:49.620566Z","iopub.execute_input":"2025-01-17T19:28:49.620845Z","iopub.status.idle":"2025-01-17T19:28:49.685601Z","shell.execute_reply.started":"2025-01-17T19:28:49.620824Z","shell.execute_reply":"2025-01-17T19:28:49.684936Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"enhanced = light_enhancement.predict(np.expand_dims(denoised, axis=0))[0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-17T19:28:51.124267Z","iopub.execute_input":"2025-01-17T19:28:51.124624Z","iopub.status.idle":"2025-01-17T19:28:51.192557Z","shell.execute_reply.started":"2025-01-17T19:28:51.124596Z","shell.execute_reply":"2025-01-17T19:28:51.191599Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"predict_images3(input_img,denoised,enhanced)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-17T19:28:53.636764Z","iopub.execute_input":"2025-01-17T19:28:53.637086Z","iopub.status.idle":"2025-01-17T19:28:54.042126Z","shell.execute_reply.started":"2025-01-17T19:28:53.637060Z","shell.execute_reply":"2025-01-17T19:28:54.041218Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"input4 = \"/kaggle/input/final-testing/test17_img.jpg\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-17T19:52:11.019735Z","iopub.execute_input":"2025-01-17T19:52:11.020029Z","iopub.status.idle":"2025-01-17T19:52:11.023590Z","shell.execute_reply.started":"2025-01-17T19:52:11.020007Z","shell.execute_reply":"2025-01-17T19:52:11.022667Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"img = cv.imread(input4, cv.IMREAD_COLOR) \nimg = cv.cvtColor(img, cv.COLOR_BGR2RGB)\nimg = cv.resize(img, (256, 256))\nimg = img.astype('float32') / 255.0\n\nimg_tensortest = tf.convert_to_tensor(img, dtype=tf.float32)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-17T19:52:12.333100Z","iopub.execute_input":"2025-01-17T19:52:12.333461Z","iopub.status.idle":"2025-01-17T19:52:12.346499Z","shell.execute_reply.started":"2025-01-17T19:52:12.333431Z","shell.execute_reply":"2025-01-17T19:52:12.345672Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"if isinstance(input4, str):  # If it's a file path\n    input_img = cv.cvtColor(cv.imread(input4), cv.COLOR_BGR2RGB)\n    input_img = input_img.astype('float32') / 255.0  # Normalize to [0, 1]\nelif isinstance(input4, np.ndarray):  # If it's already an array\n    input_img = (input4 * 255).astype('uint8')\nelse:  # Handle tensors\n    input_img = (input4.numpy() * 255).astype('uint8')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-17T19:52:15.287215Z","iopub.execute_input":"2025-01-17T19:52:15.287562Z","iopub.status.idle":"2025-01-17T19:52:15.296302Z","shell.execute_reply.started":"2025-01-17T19:52:15.287534Z","shell.execute_reply":"2025-01-17T19:52:15.295372Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"denoised = denoising.predict(np.expand_dims(img_tensortest, axis=0))[0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-17T19:52:17.269373Z","iopub.execute_input":"2025-01-17T19:52:17.269670Z","iopub.status.idle":"2025-01-17T19:52:17.334597Z","shell.execute_reply.started":"2025-01-17T19:52:17.269645Z","shell.execute_reply":"2025-01-17T19:52:17.333930Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"enhanced = light_enhancement.predict(np.expand_dims(denoised, axis=0))[0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-17T19:52:18.028540Z","iopub.execute_input":"2025-01-17T19:52:18.028873Z","iopub.status.idle":"2025-01-17T19:52:18.097175Z","shell.execute_reply.started":"2025-01-17T19:52:18.028839Z","shell.execute_reply":"2025-01-17T19:52:18.096509Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"predict_images3(input_img,denoised,enhanced)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-17T19:52:18.637948Z","iopub.execute_input":"2025-01-17T19:52:18.638260Z","iopub.status.idle":"2025-01-17T19:52:19.045973Z","shell.execute_reply.started":"2025-01-17T19:52:18.638235Z","shell.execute_reply":"2025-01-17T19:52:19.045107Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"input = \"/kaggle/input/final-testing/test6_img.jpg\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-17T19:29:50.402276Z","iopub.execute_input":"2025-01-17T19:29:50.402600Z","iopub.status.idle":"2025-01-17T19:29:50.406267Z","shell.execute_reply.started":"2025-01-17T19:29:50.402578Z","shell.execute_reply":"2025-01-17T19:29:50.405421Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"img = cv.imread(input, cv.IMREAD_COLOR) \nimg = cv.cvtColor(img, cv.COLOR_BGR2RGB)\nimg = cv.resize(img, (256, 256))\nimg = img.astype('float32') / 255.0\n\nimg_tensortest = tf.convert_to_tensor(img, dtype=tf.float32)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-17T19:29:52.032801Z","iopub.execute_input":"2025-01-17T19:29:52.033101Z","iopub.status.idle":"2025-01-17T19:29:52.053748Z","shell.execute_reply.started":"2025-01-17T19:29:52.033077Z","shell.execute_reply":"2025-01-17T19:29:52.053095Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"if isinstance(input, str):  # If it's a file path\n    input_img = cv.cvtColor(cv.imread(input), cv.COLOR_BGR2RGB)\n    input_img = input_img.astype('float32') / 255.0  # Normalize to [0, 1]\nelif isinstance(input, np.ndarray):  # If it's already an array\n    input_img = (input * 255).astype('uint8')\nelse:  # Handle tensors\n    input_img = (input.numpy() * 255).astype('uint8')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-17T19:29:53.667078Z","iopub.execute_input":"2025-01-17T19:29:53.667418Z","iopub.status.idle":"2025-01-17T19:29:53.681018Z","shell.execute_reply.started":"2025-01-17T19:29:53.667394Z","shell.execute_reply":"2025-01-17T19:29:53.680272Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"denoised = denoising.predict(np.expand_dims(img_tensortest, axis=0))[0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-17T19:29:55.114683Z","iopub.execute_input":"2025-01-17T19:29:55.114961Z","iopub.status.idle":"2025-01-17T19:29:55.179165Z","shell.execute_reply.started":"2025-01-17T19:29:55.114938Z","shell.execute_reply":"2025-01-17T19:29:55.178539Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"enhanced = light_enhancement.predict(np.expand_dims(denoised, axis=0))[0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-17T19:29:56.747153Z","iopub.execute_input":"2025-01-17T19:29:56.747542Z","iopub.status.idle":"2025-01-17T19:29:56.815979Z","shell.execute_reply.started":"2025-01-17T19:29:56.747501Z","shell.execute_reply":"2025-01-17T19:29:56.815121Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"predict_images3(input_img,denoised,enhanced)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-17T19:29:58.211024Z","iopub.execute_input":"2025-01-17T19:29:58.211364Z","iopub.status.idle":"2025-01-17T19:29:58.714410Z","shell.execute_reply.started":"2025-01-17T19:29:58.211320Z","shell.execute_reply":"2025-01-17T19:29:58.713464Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"input = \"/kaggle/input/final-testing/test7_img.jpg\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-17T19:30:08.017789Z","iopub.execute_input":"2025-01-17T19:30:08.018104Z","iopub.status.idle":"2025-01-17T19:30:08.021752Z","shell.execute_reply.started":"2025-01-17T19:30:08.018081Z","shell.execute_reply":"2025-01-17T19:30:08.020894Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"img = cv.imread(input, cv.IMREAD_COLOR) \nimg = cv.cvtColor(img, cv.COLOR_BGR2RGB)\nimg = cv.resize(img, (256, 256))\nimg = img.astype('float32') / 255.0\n\nimg_tensortest = tf.convert_to_tensor(img, dtype=tf.float32)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-17T19:30:09.613402Z","iopub.execute_input":"2025-01-17T19:30:09.613724Z","iopub.status.idle":"2025-01-17T19:30:09.638876Z","shell.execute_reply.started":"2025-01-17T19:30:09.613693Z","shell.execute_reply":"2025-01-17T19:30:09.637730Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"if isinstance(input, str):  # If it's a file path\n    input_img = cv.cvtColor(cv.imread(input), cv.COLOR_BGR2RGB)\n    input_img = input_img.astype('float32') / 255.0  # Normalize to [0, 1]\nelif isinstance(input, np.ndarray):  # If it's already an array\n    input_img = (input * 255).astype('uint8')\nelse:  # Handle tensors\n    input_img = (input.numpy() * 255).astype('uint8')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-17T19:30:11.208919Z","iopub.execute_input":"2025-01-17T19:30:11.209227Z","iopub.status.idle":"2025-01-17T19:30:11.231580Z","shell.execute_reply.started":"2025-01-17T19:30:11.209205Z","shell.execute_reply":"2025-01-17T19:30:11.230913Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"denoised = denoising.predict(np.expand_dims(img_tensortest, axis=0))[0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-17T19:30:12.683169Z","iopub.execute_input":"2025-01-17T19:30:12.683498Z","iopub.status.idle":"2025-01-17T19:30:12.747867Z","shell.execute_reply.started":"2025-01-17T19:30:12.683472Z","shell.execute_reply":"2025-01-17T19:30:12.746919Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"enhanced = light_enhancement.predict(np.expand_dims(denoised, axis=0))[0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-17T19:30:14.236389Z","iopub.execute_input":"2025-01-17T19:30:14.236721Z","iopub.status.idle":"2025-01-17T19:30:14.302332Z","shell.execute_reply.started":"2025-01-17T19:30:14.236698Z","shell.execute_reply":"2025-01-17T19:30:14.301705Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"predict_images3(input_img,denoised,enhanced)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-17T19:30:15.604794Z","iopub.execute_input":"2025-01-17T19:30:15.605091Z","iopub.status.idle":"2025-01-17T19:30:16.243500Z","shell.execute_reply.started":"2025-01-17T19:30:15.605069Z","shell.execute_reply":"2025-01-17T19:30:16.242718Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"input = \"/kaggle/input/final-testing/test8_img.png\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-17T19:30:17.221271Z","iopub.execute_input":"2025-01-17T19:30:17.221600Z","iopub.status.idle":"2025-01-17T19:30:17.225214Z","shell.execute_reply.started":"2025-01-17T19:30:17.221576Z","shell.execute_reply":"2025-01-17T19:30:17.224386Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"img = cv.imread(input, cv.IMREAD_COLOR) \nimg = cv.cvtColor(img, cv.COLOR_BGR2RGB)\nimg = cv.resize(img, (256, 256))\nimg = img.astype('float32') / 255.0\n\nimg_tensortest = tf.convert_to_tensor(img, dtype=tf.float32)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-17T19:30:32.443393Z","iopub.execute_input":"2025-01-17T19:30:32.443843Z","iopub.status.idle":"2025-01-17T19:30:32.469314Z","shell.execute_reply.started":"2025-01-17T19:30:32.443795Z","shell.execute_reply":"2025-01-17T19:30:32.468433Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"if isinstance(input, str):  # If it's a file path\n    input_img = cv.cvtColor(cv.imread(input), cv.COLOR_BGR2RGB)\n    input_img = input_img.astype('float32') / 255.0  # Normalize to [0, 1]\nelif isinstance(input, np.ndarray):  # If it's already an array\n    input_img = (input * 255).astype('uint8')\nelse:  # Handle tensors\n    input_img = (input.numpy() * 255).astype('uint8')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-17T19:30:34.088154Z","iopub.execute_input":"2025-01-17T19:30:34.088487Z","iopub.status.idle":"2025-01-17T19:30:34.103914Z","shell.execute_reply.started":"2025-01-17T19:30:34.088459Z","shell.execute_reply":"2025-01-17T19:30:34.102999Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"denoised = denoising.predict(np.expand_dims(img_tensortest, axis=0))[0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-17T19:30:35.669154Z","iopub.execute_input":"2025-01-17T19:30:35.669538Z","iopub.status.idle":"2025-01-17T19:30:35.732409Z","shell.execute_reply.started":"2025-01-17T19:30:35.669507Z","shell.execute_reply":"2025-01-17T19:30:35.731686Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"enhanced = light_enhancement.predict(np.expand_dims(denoised, axis=0))[0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-17T19:30:37.141335Z","iopub.execute_input":"2025-01-17T19:30:37.141679Z","iopub.status.idle":"2025-01-17T19:30:37.210877Z","shell.execute_reply.started":"2025-01-17T19:30:37.141651Z","shell.execute_reply":"2025-01-17T19:30:37.210153Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"predict_images3(input_img,denoised,enhanced)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-17T19:30:38.843403Z","iopub.execute_input":"2025-01-17T19:30:38.843727Z","iopub.status.idle":"2025-01-17T19:30:39.262880Z","shell.execute_reply.started":"2025-01-17T19:30:38.843700Z","shell.execute_reply":"2025-01-17T19:30:39.261929Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"input = \"/kaggle/input/final-testing/test11_img.jpg\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-17T19:30:43.043424Z","iopub.execute_input":"2025-01-17T19:30:43.043752Z","iopub.status.idle":"2025-01-17T19:30:43.047594Z","shell.execute_reply.started":"2025-01-17T19:30:43.043723Z","shell.execute_reply":"2025-01-17T19:30:43.046771Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"img = cv.imread(input, cv.IMREAD_COLOR) \nimg = cv.cvtColor(img, cv.COLOR_BGR2RGB)\nimg = cv.resize(img, (256, 256))\nimg = img.astype('float32') / 255.0\n\nimg_tensortest = tf.convert_to_tensor(img, dtype=tf.float32)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-17T19:30:45.266436Z","iopub.execute_input":"2025-01-17T19:30:45.266722Z","iopub.status.idle":"2025-01-17T19:30:45.297032Z","shell.execute_reply.started":"2025-01-17T19:30:45.266700Z","shell.execute_reply":"2025-01-17T19:30:45.296338Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"if isinstance(input, str):  # If it's a file path\n    input_img = cv.cvtColor(cv.imread(input), cv.COLOR_BGR2RGB)\n    input_img = input_img.astype('float32') / 255.0  # Normalize to [0, 1]\nelif isinstance(input, np.ndarray):  # If it's already an array\n    input_img = (input * 255).astype('uint8')\nelse:  # Handle tensors\n    input_img = (input.numpy() * 255).astype('uint8')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-17T19:30:47.243817Z","iopub.execute_input":"2025-01-17T19:30:47.244114Z","iopub.status.idle":"2025-01-17T19:30:47.269976Z","shell.execute_reply.started":"2025-01-17T19:30:47.244090Z","shell.execute_reply":"2025-01-17T19:30:47.269108Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"denoised = denoising.predict(np.expand_dims(img_tensortest, axis=0))[0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-17T19:30:49.492862Z","iopub.execute_input":"2025-01-17T19:30:49.493178Z","iopub.status.idle":"2025-01-17T19:30:49.558507Z","shell.execute_reply.started":"2025-01-17T19:30:49.493150Z","shell.execute_reply":"2025-01-17T19:30:49.557653Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"enhanced = light_enhancement.predict(np.expand_dims(denoised, axis=0))[0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-17T19:30:50.910446Z","iopub.execute_input":"2025-01-17T19:30:50.910762Z","iopub.status.idle":"2025-01-17T19:30:50.976945Z","shell.execute_reply.started":"2025-01-17T19:30:50.910738Z","shell.execute_reply":"2025-01-17T19:30:50.976284Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"output = resolution.predict(np.expand_dims(enhanced, axis=0))[0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-17T19:30:52.455202Z","iopub.execute_input":"2025-01-17T19:30:52.455562Z","iopub.status.idle":"2025-01-17T19:30:52.924140Z","shell.execute_reply.started":"2025-01-17T19:30:52.455530Z","shell.execute_reply":"2025-01-17T19:30:52.923493Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"predict_images4(input_img,denoised,enhanced,output)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-17T19:30:56.320597Z","iopub.execute_input":"2025-01-17T19:30:56.320932Z","iopub.status.idle":"2025-01-17T19:30:56.969158Z","shell.execute_reply.started":"2025-01-17T19:30:56.320907Z","shell.execute_reply":"2025-01-17T19:30:56.968231Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"input = \"/kaggle/input/final-testing/test20_img.png\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-17T19:48:02.485491Z","iopub.execute_input":"2025-01-17T19:48:02.485813Z","iopub.status.idle":"2025-01-17T19:48:02.489607Z","shell.execute_reply.started":"2025-01-17T19:48:02.485790Z","shell.execute_reply":"2025-01-17T19:48:02.488506Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"img = cv.imread(input, cv.IMREAD_COLOR) \nimg = cv.cvtColor(img, cv.COLOR_BGR2RGB)\nimg = cv.resize(img, (256, 256))\nimg = img.astype('float32') / 255.0\n\nimg_tensortest = tf.convert_to_tensor(img, dtype=tf.float32)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-17T19:48:04.685298Z","iopub.execute_input":"2025-01-17T19:48:04.685639Z","iopub.status.idle":"2025-01-17T19:48:04.707071Z","shell.execute_reply.started":"2025-01-17T19:48:04.685610Z","shell.execute_reply":"2025-01-17T19:48:04.706422Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"if isinstance(input, str):  # If it's a file path\n    input_img = cv.cvtColor(cv.imread(input), cv.COLOR_BGR2RGB)\n    input_img = input_img.astype('float32') / 255.0  # Normalize to [0, 1]\nelif isinstance(input, np.ndarray):  # If it's already an array\n    input_img = (input * 255).astype('uint8')\nelse:  # Handle tensors\n    input_img = (input.numpy() * 255).astype('uint8')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-17T19:48:06.757710Z","iopub.execute_input":"2025-01-17T19:48:06.757999Z","iopub.status.idle":"2025-01-17T19:48:06.770765Z","shell.execute_reply.started":"2025-01-17T19:48:06.757974Z","shell.execute_reply":"2025-01-17T19:48:06.769994Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"denoised = denoising.predict(np.expand_dims(img_tensortest, axis=0))[0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-17T19:48:11.424559Z","iopub.execute_input":"2025-01-17T19:48:11.424838Z","iopub.status.idle":"2025-01-17T19:48:11.487839Z","shell.execute_reply.started":"2025-01-17T19:48:11.424816Z","shell.execute_reply":"2025-01-17T19:48:11.487266Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"enhanced = light_enhancement.predict(np.expand_dims(denoised, axis=0))[0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-17T19:48:12.502054Z","iopub.execute_input":"2025-01-17T19:48:12.502381Z","iopub.status.idle":"2025-01-17T19:48:12.567929Z","shell.execute_reply.started":"2025-01-17T19:48:12.502329Z","shell.execute_reply":"2025-01-17T19:48:12.567285Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"predict_images3(input_img,denoised,enhanced)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-17T19:48:14.820218Z","iopub.execute_input":"2025-01-17T19:48:14.820606Z","iopub.status.idle":"2025-01-17T19:48:15.137501Z","shell.execute_reply.started":"2025-01-17T19:48:14.820577Z","shell.execute_reply":"2025-01-17T19:48:15.136573Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"input = \"/kaggle/input/final-testing/test19_img.png\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-17T19:45:21.727926Z","iopub.execute_input":"2025-01-17T19:45:21.728232Z","iopub.status.idle":"2025-01-17T19:45:21.731907Z","shell.execute_reply.started":"2025-01-17T19:45:21.728207Z","shell.execute_reply":"2025-01-17T19:45:21.731137Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"img = cv.imread(input, cv.IMREAD_COLOR) \nimg = cv.cvtColor(img, cv.COLOR_BGR2RGB)\nimg = cv.resize(img, (256, 256))\nimg = img.astype('float32') / 255.0\n\nimg_tensortest = tf.convert_to_tensor(img, dtype=tf.float32)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-17T19:45:22.878552Z","iopub.execute_input":"2025-01-17T19:45:22.878842Z","iopub.status.idle":"2025-01-17T19:45:22.899544Z","shell.execute_reply.started":"2025-01-17T19:45:22.878819Z","shell.execute_reply":"2025-01-17T19:45:22.898778Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"if isinstance(input, str):  # If it's a file path\n    input_img = cv.cvtColor(cv.imread(input), cv.COLOR_BGR2RGB)\n    input_img = input_img.astype('float32') / 255.0  # Normalize to [0, 1]\nelif isinstance(input, np.ndarray):  # If it's already an array\n    input_img = (input * 255).astype('uint8')\nelse:  # Handle tensors\n    input_img = (input.numpy() * 255).astype('uint8')","metadata":{"trusted":true,"_kg_hide-input":true,"execution":{"iopub.status.busy":"2025-01-17T19:45:24.105101Z","iopub.execute_input":"2025-01-17T19:45:24.105444Z","iopub.status.idle":"2025-01-17T19:45:24.118178Z","shell.execute_reply.started":"2025-01-17T19:45:24.105417Z","shell.execute_reply":"2025-01-17T19:45:24.117203Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"denoised = denoising.predict(np.expand_dims(img_tensortest, axis=0))[0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-17T19:45:25.800133Z","iopub.execute_input":"2025-01-17T19:45:25.800453Z","iopub.status.idle":"2025-01-17T19:45:25.864885Z","shell.execute_reply.started":"2025-01-17T19:45:25.800428Z","shell.execute_reply":"2025-01-17T19:45:25.864246Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"enhanced = light_enhancement.predict(np.expand_dims(denoised, axis=0))[0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-17T19:45:27.208995Z","iopub.execute_input":"2025-01-17T19:45:27.209340Z","iopub.status.idle":"2025-01-17T19:45:27.277054Z","shell.execute_reply.started":"2025-01-17T19:45:27.209313Z","shell.execute_reply":"2025-01-17T19:45:27.276119Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"predict_images3(input_img,denoised,enhanced)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-17T19:45:28.565406Z","iopub.execute_input":"2025-01-17T19:45:28.565732Z","iopub.status.idle":"2025-01-17T19:45:28.890673Z","shell.execute_reply.started":"2025-01-17T19:45:28.565706Z","shell.execute_reply":"2025-01-17T19:45:28.889794Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}